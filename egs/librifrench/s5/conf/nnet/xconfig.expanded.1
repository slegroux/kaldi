# This file was created by the command:
# steps/nnet3/xconfig_to_configs.py --xconfig-file conf/nnet/network.xconfig --config-dir conf/nnet/
#It contains the same content as ./xconfig but it was parsed and
#default config values were set.
# See also ./xconfig.expanded.2

input name=input dim=13
relu-renorm-layer name=tdnn1 add-log-stddev=False bias-stddev= bottleneck-dim=-1 dim=8 dropout-per-dim=False dropout-per-dim-continuous=False dropout-proportion=0.5 input=Append(input@-2,input@-1,input,input@1,input@2) l2-regularize= learning-rate-factor= max-change=0.75 ng-affine-options= ng-linear-options= self-repair-scale=1e-05 target-rms=1.0
relu-renorm-layer name=tdnn2 add-log-stddev=False bias-stddev= bottleneck-dim=-1 dim=8 dropout-per-dim=False dropout-per-dim-continuous=False dropout-proportion=0.5 input=[-1] l2-regularize= learning-rate-factor= max-change=0.75 ng-affine-options= ng-linear-options= self-repair-scale=1e-05 target-rms=1.0
relu-renorm-layer name=tdnn3 add-log-stddev=False bias-stddev= bottleneck-dim=-1 dim=8 dropout-per-dim=False dropout-per-dim-continuous=False dropout-proportion=0.5 input=Append(-1,2) l2-regularize= learning-rate-factor= max-change=0.75 ng-affine-options= ng-linear-options= self-repair-scale=1e-05 target-rms=1.0
relu-renorm-layer name=tdnn4 add-log-stddev=False bias-stddev= bottleneck-dim=-1 dim=8 dropout-per-dim=False dropout-per-dim-continuous=False dropout-proportion=0.5 input=Append(-3,3) l2-regularize= learning-rate-factor= max-change=0.75 ng-affine-options= ng-linear-options= self-repair-scale=1e-05 target-rms=1.0
relu-renorm-layer name=tdnn5 add-log-stddev=False bias-stddev= bottleneck-dim=-1 dim=8 dropout-per-dim=False dropout-per-dim-continuous=False dropout-proportion=0.5 input=Append(-3,3) l2-regularize= learning-rate-factor= max-change=0.75 ng-affine-options= ng-linear-options= self-repair-scale=1e-05 target-rms=1.0
relu-renorm-layer name=tdnn6 add-log-stddev=False bias-stddev= bottleneck-dim=-1 dim=8 dropout-per-dim=False dropout-per-dim-continuous=False dropout-proportion=0.5 input=Append(-3,3) l2-regularize= learning-rate-factor= max-change=0.75 ng-affine-options= ng-linear-options= self-repair-scale=1e-05 target-rms=1.0
relu-renorm-layer name=tdnn7 add-log-stddev=False bias-stddev= bottleneck-dim=-1 dim=8 dropout-per-dim=False dropout-per-dim-continuous=False dropout-proportion=0.5 input=Append(-3,3) l2-regularize= learning-rate-factor= max-change=0.75 ng-affine-options= ng-linear-options= self-repair-scale=1e-05 target-rms=1.0
relu-renorm-layer name=tdnn8 add-log-stddev=False bias-stddev= bottleneck-dim=-1 dim=8 dropout-per-dim=False dropout-per-dim-continuous=False dropout-proportion=0.5 input=Append(-3,3) l2-regularize= learning-rate-factor= max-change=0.75 ng-affine-options= ng-linear-options= self-repair-scale=1e-05 target-rms=1.0
relu-renorm-layer name=tdnn9 add-log-stddev=False bias-stddev= bottleneck-dim=-1 dim=8 dropout-per-dim=False dropout-per-dim-continuous=False dropout-proportion=0.5 input=Append(-3,3) l2-regularize= learning-rate-factor= max-change=0.75 ng-affine-options= ng-linear-options= self-repair-scale=1e-05 target-rms=1.0
relu-renorm-layer name=tdnn10 add-log-stddev=False bias-stddev= bottleneck-dim=-1 dim=8 dropout-per-dim=False dropout-per-dim-continuous=False dropout-proportion=0.5 input=Append(-3,3) l2-regularize= learning-rate-factor= max-change=0.75 ng-affine-options= ng-linear-options= self-repair-scale=1e-05 target-rms=1.0
relu-renorm-layer name=tdnn11 add-log-stddev=False bias-stddev= bottleneck-dim=-1 dim=8 dropout-per-dim=False dropout-per-dim-continuous=False dropout-proportion=0.5 input=Append(-3,3) l2-regularize= learning-rate-factor= max-change=0.75 ng-affine-options= ng-linear-options= self-repair-scale=1e-05 target-rms=1.0
relu-renorm-layer name=tdnnFINAL add-log-stddev=False bias-stddev= bottleneck-dim=-1 dim=8 dropout-per-dim=False dropout-per-dim-continuous=False dropout-proportion=0.5 input=Append(-3,3) l2-regularize= learning-rate-factor= max-change=0.75 ng-affine-options= ng-linear-options= self-repair-scale=1e-05 target-rms=1.0
relu-renorm-layer name=prefinal-affine-layer add-log-stddev=False bias-stddev= bottleneck-dim=-1 dim=8 dropout-per-dim=False dropout-per-dim-continuous=False dropout-proportion=0.5 input=tdnnFINAL l2-regularize= learning-rate-factor= max-change=0.75 ng-affine-options= ng-linear-options= self-repair-scale=1e-05 target-rms=1.0
output-layer name=output bias-stddev=0.0 bottleneck-dim=-1 dim=3056 include-log-softmax=True input=[-1] l2-regularize= learning-rate-factor= max-change=1.5 ng-affine-options= ng-linear-options= objective-type=linear orthonormal-constraint=1.0 output-delay=0 param-stddev=0.0
